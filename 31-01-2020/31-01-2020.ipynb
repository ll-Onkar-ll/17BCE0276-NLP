{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cruelti'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "stem_porter = PorterStemmer()\n",
    "stem_porter.stem(\"cruelty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lie\n",
      "tri\n",
      "tie\n",
      "cri\n",
      "sy\n",
      "die\n",
      "dye\n",
      "vy\n",
      "vilifi\n",
      "impress\n",
      "lazi\n"
     ]
    }
   ],
   "source": [
    "print(stem_porter.stem(\"lying\"))\n",
    "print(stem_porter.stem(\"trying\"))\n",
    "print(stem_porter.stem(\"tying\"))\n",
    "print(stem_porter.stem(\"crying\"))\n",
    "print(stem_porter.stem(\"sying\")) #random invalid 'ying' word\n",
    "print(stem_porter.stem(\"dying\"))\n",
    "print(stem_porter.stem(\"dyeing\"))\n",
    "print(stem_porter.stem(\"vying\")) #didn't work for a similar valid 'ying' word\n",
    "print(stem_porter.stem(\"vilify\"))\n",
    "print(stem_porter.stem(\"impressive\"))\n",
    "print(stem_porter.stem(\"laziness\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fantast'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import LancasterStemmer\n",
    "stemmer = LancasterStemmer()\n",
    "stemmer.stem(\"fantastical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lying\n",
      "try\n",
      "tying\n",
      "cry\n",
      "sying\n",
      "dying\n",
      "dye\n",
      "vying\n",
      "vil\n",
      "impress\n",
      "lazy\n"
     ]
    }
   ],
   "source": [
    "print(stemmer.stem(\"lying\"))\n",
    "print(stemmer.stem(\"trying\"))\n",
    "print(stemmer.stem(\"tying\"))\n",
    "print(stemmer.stem(\"crying\"))\n",
    "print(stemmer.stem(\"sying\")) #random invalid 'ying' word\n",
    "print(stemmer.stem(\"dying\"))\n",
    "print(stemmer.stem(\"dyeing\"))\n",
    "print(stemmer.stem(\"vying\"))\n",
    "print(stemmer.stem(\"vilify\"))\n",
    "print(stemmer.stem(\"impressive\"))\n",
    "print(stemmer.stem(\"laziness\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ly\n",
      "try\n",
      "ty\n",
      "cry\n",
      "sy\n",
      "dy\n",
      "dye\n",
      "vy\n",
      "vilify\n",
      "impressive\n",
      "laziness\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import RegexpStemmer\n",
    "stemmer = RegexpStemmer(\"ing\")\n",
    "print(stemmer.stem(\"lying\"))\n",
    "print(stemmer.stem(\"trying\"))\n",
    "print(stemmer.stem(\"tying\"))\n",
    "print(stemmer.stem(\"crying\"))\n",
    "print(stemmer.stem(\"sying\")) #random invalid 'ying' word\n",
    "print(stemmer.stem(\"dying\"))\n",
    "print(stemmer.stem(\"dyeing\"))\n",
    "print(stemmer.stem(\"vying\"))\n",
    "print(stemmer.stem(\"vilify\"))\n",
    "print(stemmer.stem(\"impressive\"))\n",
    "print(stemmer.stem(\"laziness\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lie\n",
      "tri\n",
      "tie\n",
      "cri\n",
      "sy\n",
      "die\n",
      "dye\n",
      "vy\n",
      "vilifi\n",
      "impress\n",
      "lazi\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "print(stemmer.stem(\"lying\"))\n",
    "print(stemmer.stem(\"trying\"))\n",
    "print(stemmer.stem(\"tying\"))\n",
    "print(stemmer.stem(\"crying\"))\n",
    "print(stemmer.stem(\"sying\")) #random invalid 'ying' word\n",
    "print(stemmer.stem(\"dying\"))\n",
    "print(stemmer.stem(\"dyeing\"))\n",
    "print(stemmer.stem(\"vying\"))\n",
    "print(stemmer.stem(\"vilify\"))\n",
    "print(stemmer.stem(\"impressive\"))\n",
    "print(stemmer.stem(\"laziness\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cactus\n",
      "mouse\n",
      "rock\n",
      "eating\n",
      "slept\n",
      "goose\n",
      "teeth\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "print(lemmatizer.lemmatize(\"cacti\"))\n",
    "print(lemmatizer.lemmatize(\"mice\"))\n",
    "print(lemmatizer.lemmatize(\"rocks\"))\n",
    "print(lemmatizer.lemmatize(\"eating\"))\n",
    "print(lemmatizer.lemmatize(\"slept\"))\n",
    "print(lemmatizer.lemmatize(\"geese\"))\n",
    "print(lemmatizer.lemmatize(\"teeth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "be\n",
      "good\n"
     ]
    }
   ],
   "source": [
    "print(lemmatizer.lemmatize(\"am\", pos = \"v\"))\n",
    "print(lemmatizer.lemmatize(\"better\", pos = \"a\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Am quick brown fox jump over the laziest dog\n"
     ]
    }
   ],
   "source": [
    "example = \"Am quick brown fox jumps over the laziest dog\"\n",
    "example = [stem_porter.stem(token) for token in example.split()]\n",
    "print(\" \".join(example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exampl are super fun, at least from the author' point of view.\n"
     ]
    }
   ],
   "source": [
    "example = \"Examples are super fun, at least from the author's point of view.\"\n",
    "example = [stem_porter.stem(token) for token in example.split()]\n",
    "print(\" \".join(example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['all', 'at', 'comes', 'document', 'fact', 'first', 'here', 'in', 'is', 'it', 'not', 'one', 'second', 'simple', 'the', 'third', 'this', 'too']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "corpus = [\n",
    "    \"A simple document; the first one in fact.\",\n",
    "    \"Here comes the second document. It's simple too.\",\n",
    "    \"This is the third document. Not simple at all.\"\n",
    "]\n",
    "\n",
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(corpus) \n",
    "print(cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 1 1 1 0 1 0 0 0 1 0 1 1 0 0 0]\n",
      " [0 0 1 1 0 0 1 0 0 1 0 0 1 1 1 0 0 1]\n",
      " [1 1 0 1 0 0 0 0 1 0 1 0 0 1 1 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
